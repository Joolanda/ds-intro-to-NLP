{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Zero-Shot Learning?\n",
    "\n",
    "- <span style=\"color:green\"> **Zero-Shot Learning** </span> is a concept, that a model when trained on enough unlabeled data (unsupervised learning) is able to generalize/ recognize at inference time even though the model was not trained on the inference data. This can be used in NLP, Images etc.\n",
    "- <span style=\"color:green\"> **Zero-Shot Learning** </span> is a setup in which a model can learn to recognize things that it hasn’t explicitly seen before in training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load useful libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    \"data/SMSSpamCollection.txt\",\n",
    "    encoding=\"utf-8\",\n",
    "    header=None,\n",
    "    delimiter=\"\\t\",\n",
    "    names=[\"target\", \"text\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                               text\n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5572 rows in the dataset\n"
     ]
    }
   ],
   "source": [
    "print(f'There are {data.shape[0]} rows in the dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the pipeline in one-line of code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to FacebookAI/roberta-large-mnli and revision 130fb28 (https://huggingface.co/FacebookAI/roberta-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/Users/jopanda/.pyenv/versions/3.11.3/lib/python3.11/site-packages/huggingface_hub/file_download.py:949: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34d7fde9b3754fe296c4bfc31680c67a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/688 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3420fcdedd184259b618b7f2915911c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.43G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-10 22:01:16.095450: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3\n",
      "2026-02-10 22:01:16.095546: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2026-02-10 22:01:16.095570: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2026-02-10 22:01:16.095997: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2026-02-10 22:01:16.096012: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "All PyTorch model weights were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cff13fdecc284b7ba793dc9e127112ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a552b27451a4604bfbb6f466438866b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeabcd56a6b24f7b986f8edbd0a3885b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5ad4b39b75c4d3fbf30bdea2c5c6028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\",device = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model works best with informative labels, spam/ham are not so informative. Using spam/ham leads to a Hamming loss of 53% vs using click bait/written by humans leading to 19%\n",
    "\n",
    "Can you find better label descriptions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_map = {\"spam\":\"click bait\", \"ham\":\"written by humans\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:32<00:00,  3.11it/s]\n"
     ]
    }
   ],
   "source": [
    "candidate_labels = list(category_map.values())\n",
    "predictedCategories = []\n",
    "trueCategories = []\n",
    "for i in tqdm(range(100)):\n",
    "    text = data.iloc[i,]['text']\n",
    "    cat = [data.iloc[i,]['target']]\n",
    "    res = classifier(text, candidate_labels, multi_label=False)\n",
    "    labels = res['labels'] \n",
    "    scores = res['scores'] #extracting the scores associated with the labels\n",
    "    res_dict = {label : score for label,score in zip(labels, scores)}\n",
    "    sorted_dict = dict(sorted(res_dict.items(), key=lambda x:x[1],reverse = True)) #sorting the dictionary of labels in descending order based on their score\n",
    "    categories  = next(k for i, (k,v) in enumerate(sorted_dict.items()))\n",
    "\n",
    "    predictedCategories.append(categories)\n",
    "    trueCats = [category_map[x] for x in cat]\n",
    "    trueCategories.append(trueCats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Categories ['normal personal SMS message between friends or family, not advertising']\n",
      "Predicted Categories unwanted SMS spam with promotions, prizes, or advertisements\n",
      "##################################################\n",
      "True Categories ['normal personal SMS message between friends or family, not advertising']\n",
      "Predicted Categories normal personal SMS message between friends or family, not advertising\n",
      "##################################################\n",
      "True Categories ['unwanted SMS spam with promotions, prizes, or advertisements']\n",
      "Predicted Categories unwanted SMS spam with promotions, prizes, or advertisements\n",
      "##################################################\n"
     ]
    }
   ],
   "source": [
    "for y_true, y_pred in zip(trueCategories[:3], predictedCategories[:3]):\n",
    "    print(f'True Categories {y_true}')\n",
    "    print(f'Predicted Categories {y_pred}')\n",
    "    print('#'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hamming Loss\n",
    "The Hamming loss is the fraction of labels that are incorrectly predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hamming loss is 0.6000 compared to 0.0237 from the last trained model in Notebook 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import hamming_loss\n",
    "print(f'The hamming loss is {hamming_loss(trueCategories,predictedCategories):.4f} compared to 0.0237 from the last trained model in Notebook 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing dataset-styles:\n",
    "The hamming loss was 0.1900  before replacing it with this very explicit, dataset‑style:\n",
    "\n",
    "category_map = {\n",
    "    \"spam\": \"unwanted SMS spam with promotions, prizes, or advertisements\",\n",
    "    \"ham\":  \"normal personal SMS message between friends or family, not advertising\"\n",
    "}\n",
    "\n",
    "compared to 0.0237 from the last trained model in Notebook 1\n",
    "\n",
    "and now with option 1 the hamming-loss was 0.6000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check your understanding\n",
    "\n",
    "Can you find better \"labels\" for the category description improve the Hamming Loss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_map = {\n",
    "    \"spam\": \"unwanted SMS spam with promotions, prizes, or advertisements\",\n",
    "    \"ham\":  \"normal personal SMS message between friends or family, not advertising\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing to the very explicit, dataset‑style labels actually made the zero‑shot model worse, not better (Hamming loss from ~0.19 → ~0.60)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our trained model in Notebook 1 (Hamming loss ≈ 0.0237) has actually seen the dataset and learned dataset‑specific patterns.\n",
    "A generic zero‑shot model hasn’t seen this dataset; 0.19 is already quite reasonable for true zero‑shot. Beating 0.0237 with zero‑shot is very unlikely.\n",
    "\n",
    "in other words:\n",
    "Notebook 1 model (0.0237): trained, task‑specific, much better - as expected.\n",
    "Zero‑shot with “click bait / written by humans” (≈0.19): quite decent zero‑shot result.\n",
    "Zero‑shot with very explicit dataset‑style labels (≈0.60): label wording is misaligned with how the NLI model understands categories.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: make the task more “SMS‑aware”\n",
    "If you want to experiment one step deeper, you can help the model by changing the hypothesis template to make it explicitly about SMS:\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"facebook/bart-large-mnli\",\n",
    "    device=0,\n",
    "    hypothesis_template=\"This SMS message is {}.\"\n",
    ")\n",
    "Then you can even try simpler labels again:\n",
    "\n",
    "category_map = {\n",
    "    \"spam\": \"spam\",\n",
    "    \"ham\":  \"not spam\",\n",
    "}\n",
    "Sometimes just telling the model the domain (“This SMS message …”) helps it interpret “spam / not spam” better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
